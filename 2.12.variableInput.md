Revisiting our old O(n) code again, below is a trick that is played in the interviews:

     function log(a, b) {
          for (let i = 0; i < a; i++) {
            console.log(i);
          }
          for (let j = 0; j < b; j++) {
            console.log(j);
          }
        }
      log(2, 3);

Instead of single value n, we're given multiple values to pass in as arguments thus we can't just drop constants and simplify it to O(n). Instead, we do it like O(a + b).

Now coming to nested loops:

    function log(a,b) {
      for (let i = 0; i < a; i++) {
        for (let j = 0; j < b; j++) {
          console.log(i, j);
        }
      }
    }

    log(5,10);

Similar to O(n), we can't drop constant and do it as O(n^2). Instead, we can do it as O(a * b). It's explained in much more detail in Q/A and stored locally.

https://www.udemy.com/course/data-structures-algorithms-javascript/learn/lecture/23531380#questions/19799452

# Below is instructor's explanation

In the first function, the time complexity is O(a+b). This is linear time complexity. It is linear because the time it takes to run the function grows directly with the size of the inputs. Comparing it with O(n), it is equivalent when a and b are approximately equal (i.e., a = b = n/2). The worst case scenario (in comparison to O(n)) is when one of the inputs is much larger than the other (i.e., a or b is near to n and the other is near to 1), but it's still linear and doesn't get worse than O(n).

In the second function, the time complexity is O(a * b). This is quadratic time complexity because for each iteration of the outer loop (of length a), the entire inner loop (of length b) is executed. Comparing it with O(n²), it is equivalent when a and b are approximately equal (i.e., a = b = sqrt(n)). The worst case scenario (in comparison to O(n²)) is when one of the inputs is much larger than the other (i.e., a or b is near to n and the other is near to 1), but it's still quadratic and doesn't get worse than O(n²).

It's worth noting that in time complexity analysis, we're most interested in how our algorithms scale with increased input size, rather than the exact number of operations. Therefore, even though the second function has a time complexity of O(a\*b), which may seem better when a and b are both smaller than n, it is still a quadratic time complexity and will scale poorly compared to linear time complexity (O(n)) as the inputs increase.
